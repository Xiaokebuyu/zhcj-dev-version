"""
Kokoro TTS ç‹¬ç«‹æµå¼æœåŠ¡ - ä¿®å¤ç‰ˆæœ¬
è§£å†³huggingface_hubæ–°ç‰ˆæœ¬å…¼å®¹é—®é¢˜
"""

import asyncio
import io
import wave
import re
import os
import time
from typing import AsyncGenerator, Optional, List, Dict, Any
from pathlib import Path
import numpy as np
from loguru import logger
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import StreamingResponse, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uuid

# ============ å›½å†…é•œåƒç«™é…ç½® ============
# ç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé¿å…APIå…¼å®¹é—®é¢˜
def setup_china_mirrors():
    """è®¾ç½®å›½å†…é•œåƒç«™ç¯å¢ƒå˜é‡"""
    mirror_config = {
        # HuggingFaceé•œåƒ - ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒ
        'HF_ENDPOINT': 'https://hf-mirror.com',
        'HUGGINGFACE_HUB_CACHE': os.path.abspath('./cache/huggingface'),
        'HF_HOME': os.path.abspath('./cache/huggingface'),
        
        # PyTorché•œåƒ
        'TORCH_HOME': os.path.abspath('./cache/torch'),
        
        # ç¦ç”¨é¥æµ‹
        'HF_HUB_DISABLE_TELEMETRY': '1',
        'DISABLE_TELEMETRY': '1',
        
        # æ€§èƒ½é…ç½®
        'OMP_NUM_THREADS': '4',
        'MKL_NUM_THREADS': '4',
        'NUMEXPR_NUM_THREADS': '4',
    }
    
    for key, value in mirror_config.items():
        os.environ[key] = value
        logger.info(f"ğŸ”§ è®¾ç½®ç¯å¢ƒå˜é‡: {key}={value}")

# åœ¨æ¨¡å—åŠ è½½æ—¶ç«‹å³è®¾ç½®
setup_china_mirrors()

# ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
os.makedirs('./cache/huggingface', exist_ok=True)
os.makedirs('./cache/torch', exist_ok=True)
os.makedirs('./logs', exist_ok=True)

# é…ç½®æ—¥å¿—
logger.add("logs/kokoro_tts.log", rotation="10 MB", level="INFO")

class TTSRequest(BaseModel):
    text: str
    voice: str = "zf_001"  # é»˜è®¤ä½¿ç”¨æŒ‡å®šçš„è¯­éŸ³
    speed: float = 1.2     # é»˜è®¤ç¨å¾®åŠ å¿«è¯­é€Ÿ
    stream: bool = True    # æ˜¯å¦æµå¼è¿”å›
    chunk_size: int = 30   # æ–‡æœ¬åˆ†å—å¤§å°

class TTSStatusResponse(BaseModel):
    success: bool
    message: str
    audio_length: Optional[float] = None
    processing_time: Optional[float] = None

class KokoroTTSService:
    """Kokoro TTS æ ¸å¿ƒæœåŠ¡ç±» - ä¿®å¤ç‰ˆæœ¬"""
    
    def __init__(self):
        self.pipeline = None
        # ğŸ”§ ä¼˜åŒ–éŸ³é¢‘å‚æ•°ï¼Œæé«˜ç”Ÿæˆé€Ÿåº¦
        self.sample_rate = int(os.getenv("KOKORO_SAMPLE_RATE", "22050"))
        self.channels = 1
        self.sample_width = 2
        self.max_chunk_length = int(os.getenv("KOKORO_MAX_CHUNK_LENGTH", "30"))
        self.chunk_delay = float(os.getenv("KOKORO_CHUNK_DELAY", "0.005"))
        self._initialize_pipeline()
    
    def _initialize_pipeline(self):
        """åˆå§‹åŒ–Kokoroç®¡é“ - ä¿®å¤ç‰ˆæœ¬"""
        try:
            logger.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ–Kokoro TTSç®¡é“...")
            
            # âœ… ä¿®å¤ï¼šç§»é™¤è¿‡æ—¶çš„constantsè®¾ç½®ï¼Œç›´æ¥ä½¿ç”¨ç¯å¢ƒå˜é‡
            logger.info(f"ğŸ“ ç¼“å­˜ç›®å½•: {os.environ.get('HUGGINGFACE_HUB_CACHE')}")
            logger.info(f"ğŸŒ HFé•œåƒ: {os.environ.get('HF_ENDPOINT')}")
            
            # å¯¼å…¥å¹¶åˆå§‹åŒ–Kokoro
            from kokoro import KPipeline
            self.pipeline = KPipeline(lang_code="z", repo_id="hexgrad/Kokoro-82M-v1.1-zh")  # ä¸­æ–‡ç®¡é“ï¼Œæ˜ç¡®æŒ‡å®šæ¨¡å‹
            logger.info("âœ… Kokoro TTS ç®¡é“åˆå§‹åŒ–æˆåŠŸ")
            
        except ImportError as e:
            logger.error("âŒ Kokoro åº“æœªå®‰è£…")
            logger.error("ğŸ’¡ è¯·è¿è¡Œå®‰è£…å‘½ä»¤:")
            logger.error("   pip install -i https://pypi.tuna.tsinghua.edu.cn/simple kokoro-tts")
            raise
        except Exception as e:
            logger.error(f"âŒ Kokoro TTS åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error("ğŸ’¡ è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯æè¿°: {str(e)}")
            
            # ğŸ”§ æ·»åŠ æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            logger.info("ğŸ” ç¯å¢ƒæ£€æŸ¥:")
            logger.info(f"   Pythonç‰ˆæœ¬: {os.sys.version}")
            logger.info(f"   å·¥ä½œç›®å½•: {os.getcwd()}")
            logger.info(f"   ç¼“å­˜ç›®å½•å­˜åœ¨: {os.path.exists('./cache/huggingface')}")
            
            # å°è¯•æ£€æŸ¥ç½‘ç»œè¿æ¥
            try:
                import requests
                response = requests.get(os.environ.get('HF_ENDPOINT', 'https://hf-mirror.com'), timeout=10)
                logger.info(f"   é•œåƒè¿æ¥çŠ¶æ€: {response.status_code}")
            except Exception as net_e:
                logger.error(f"   ç½‘ç»œè¿æ¥å¤±è´¥: {net_e}")
            
            raise
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤markdownæ ¼å¼ç­‰"""
        # ç§»é™¤ä»£ç å—
        text = re.sub(r'```[\s\S]*?```', '', text)
        # ç§»é™¤è¡Œå†…ä»£ç 
        text = re.sub(r'`([^`]+)`', r'\1', text)
        # ç§»é™¤ç²—ä½“æ ¼å¼
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
        text = re.sub(r'__([^_]+)__', r'\1', text)
        # ç§»é™¤æ–œä½“æ ¼å¼
        text = re.sub(r'\*([^*]+)\*', r'\1', text)
        text = re.sub(r'_([^_]+)_', r'\1', text)
        # ç§»é™¤åˆ é™¤çº¿
        text = re.sub(r'~~([^~]+)~~', r'\1', text)
        # ç§»é™¤æ ‡é¢˜æ ‡è®°
        text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
        # ç§»é™¤å¼•ç”¨æ ‡è®°
        text = re.sub(r'^>\s*', '', text, flags=re.MULTILINE)
        # ç§»é™¤åˆ—è¡¨æ ‡è®°
        text = re.sub(r'^[\s]*[-*+]\s+', '', text, flags=re.MULTILINE)
        text = re.sub(r'^[\s]*\d+\.\s+', '', text, flags=re.MULTILINE)
        # ç§»é™¤é“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬
        text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)
        # ç§»é™¤å›¾ç‰‡
        text = re.sub(r'!\[[^\]]*\]\([^)]+\)', '', text)
        # ç§»é™¤HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)
        # ç§»é™¤è¡¨æ ¼åˆ†éš”ç¬¦
        text = re.sub(r'\|', ' ', text)
        # æ¸…ç†å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _split_into_chunks(self, text: str, max_length: int = None) -> List[str]:
        """å°†é•¿æ–‡æœ¬åˆ†å‰²ä¸ºæ›´å°çš„å—ï¼Œæé«˜ç”Ÿæˆé€Ÿåº¦"""
        if max_length is None:
            max_length = self.max_chunk_length
            
        # é¦–å…ˆæŒ‰æ ‡ç‚¹åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ.!?])', text)
        chunks = []
        current_chunk = ""
        
        i = 0
        while i < len(sentences):
            sentence = sentences[i]
            if i + 1 < len(sentences) and sentences[i + 1] in 'ã€‚ï¼ï¼Ÿ.!?':
                sentence += sentences[i + 1]
                i += 2
            else:
                i += 1
            
            # å¦‚æœæ·»åŠ è¿™å¥è¯ä¼šè¶…è¿‡é•¿åº¦é™åˆ¶
            if len(current_chunk + sentence) > max_length and current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = sentence
            else:
                current_chunk += sentence
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        # å¦‚æœå•ä¸ªå¥å­ä»ç„¶å¤ªé•¿ï¼ŒæŒ‰è¯åˆ†å‰²
        final_chunks = []
        for chunk in chunks:
            if len(chunk) <= max_length:
                final_chunks.append(chunk)
            else:
                # æŒ‰é€—å·è¿›ä¸€æ­¥åˆ†å‰²
                sub_chunks = self._split_by_comma(chunk, max_length)
                final_chunks.extend(sub_chunks)
        
        return [chunk for chunk in final_chunks if chunk.strip()]
    
    def _split_by_comma(self, text: str, max_length: int) -> List[str]:
        """æŒ‰é€—å·åˆ†å‰²é•¿å¥"""
        parts = re.split(r'([ï¼Œ,])', text)
        chunks = []
        current_chunk = ""
        
        i = 0
        while i < len(parts):
            part = parts[i]
            if i + 1 < len(parts) and parts[i + 1] in 'ï¼Œ,':
                part += parts[i + 1]
                i += 2
            else:
                i += 1
            
            if len(current_chunk + part) > max_length and current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = part
            else:
                current_chunk += part
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def _create_wav_header(self, data_size: int = 0) -> bytes:
        """åˆ›å»ºWAVæ–‡ä»¶å¤´éƒ¨"""
        header = io.BytesIO()
        
        # RIFFå¤´éƒ¨
        header.write(b'RIFF')
        header.write((36 + data_size).to_bytes(4, 'little'))
        header.write(b'WAVE')
        
        # fmtå­å—
        header.write(b'fmt ')
        header.write((16).to_bytes(4, 'little'))
        header.write((1).to_bytes(2, 'little'))
        header.write(self.channels.to_bytes(2, 'little'))
        header.write(self.sample_rate.to_bytes(4, 'little'))
        header.write((self.sample_rate * self.channels * self.sample_width).to_bytes(4, 'little'))
        header.write((self.channels * self.sample_width).to_bytes(2, 'little'))
        header.write((self.sample_width * 8).to_bytes(2, 'little'))
        
        # dataå­å—å¤´éƒ¨
        header.write(b'data')
        header.write(data_size.to_bytes(4, 'little'))
        
        return header.getvalue()
    
    async def generate_streaming_audio(
        self, 
        text: str, 
        voice: str = "zf_001", 
        speed: float = 1.2,
        chunk_size: int = 30
    ) -> AsyncGenerator[bytes, None]:
        """ç”Ÿæˆæµå¼éŸ³é¢‘æ•°æ® - æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
        if not self.pipeline:
            logger.warning("âš ï¸ ç®¡é“æœªåˆå§‹åŒ–ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–...")
            self._initialize_pipeline()
        
        start_time = time.time()
        
        try:
            # æ¸…ç†æ–‡æœ¬
            clean_text = self._clean_text(text)
            
            if not clean_text.strip():
                logger.warning("âš ï¸ æ¸…ç†åæ–‡æœ¬ä¸ºç©º")
                return
            
            logger.info(f"ğŸ™ï¸ å¼€å§‹ç”Ÿæˆè¯­éŸ³ [voice: {voice}, speed: {speed}]: {clean_text[:50]}...")
            
            # ğŸ”§ æ™ºèƒ½åˆ†å—å¤„ç†
            if len(clean_text) > chunk_size:
                chunks = self._split_into_chunks(clean_text, chunk_size)
                logger.debug(f"ğŸ“¦ æ–‡æœ¬åˆ†ä¸º {len(chunks)} å—")
            else:
                chunks = [clean_text]
            
            # å…ˆå‘é€WAVå¤´éƒ¨
            yield self._create_wav_header(0)
            
            # æµå¼ç”ŸæˆéŸ³é¢‘
            audio_generated = False
            total_audio_bytes = 0
            
            for i, chunk in enumerate(chunks):
                if not chunk.strip():
                    continue
                
                logger.debug(f"ğŸ”Š å¤„ç†ç¬¬ {i+1}/{len(chunks)} å—: {chunk[:30]}...")
                
                try:
                    for result in self.pipeline(
                        chunk, 
                        voice=voice, 
                        speed=speed, 
                        split_pattern=r"[ã€‚ï¼ï¼Ÿ.!?]+"
                    ):
                        if result.audio is None:
                            continue
                        
                        # è½¬æ¢ä¸º16ä½PCMæ ¼å¼
                        audio_data = (result.audio.numpy() * 32767).astype(np.int16)
                        audio_bytes = audio_data.tobytes()
                        
                        total_audio_bytes += len(audio_bytes)
                        logger.debug(f"ğŸµ ç”ŸæˆéŸ³é¢‘å—: {len(audio_bytes)} å­—èŠ‚")
                        
                        yield audio_bytes
                        audio_generated = True
                        
                        # ä¼˜åŒ–å»¶è¿Ÿ
                        await asyncio.sleep(self.chunk_delay)
                        
                except Exception as chunk_error:
                    logger.error(f"âŒ å¤„ç†å— {i+1} å¤±è´¥: {chunk_error}")
                    continue
            
            processing_time = time.time() - start_time
            
            if audio_generated:
                logger.info(f"âœ… è¯­éŸ³ç”Ÿæˆå®Œæˆ: {total_audio_bytes} å­—èŠ‚, è€—æ—¶: {processing_time:.2f}ç§’")
            else:
                logger.warning("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘æ•°æ®")
                
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Kokoro TTS Service",
    description="ä¸“ä¸ºè™šæ‹Ÿä¸»æ’­AIè®¾è®¡çš„é«˜æ€§èƒ½æµå¼è¯­éŸ³åˆæˆæœåŠ¡ (ä¿®å¤ç‰ˆ)",
    version="1.1.1"
)

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€TTSæœåŠ¡å®ä¾‹
tts_service = None

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–TTSæœåŠ¡"""
    global tts_service
    try:
        logger.info("ğŸš€ æ­£åœ¨å¯åŠ¨Kokoro TTSæœåŠ¡...")
        tts_service = KokoroTTSService()
        logger.info("âœ… æœåŠ¡å¯åŠ¨æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        # ä¸ç«‹å³é€€å‡ºï¼Œå…è®¸æœåŠ¡å¯åŠ¨ä½†æ ‡è®°ä¸ºä¸å¥åº·
        tts_service = None

@app.get("/")
async def root():
    """æœåŠ¡æ ¹è·¯å¾„"""
    return {
        "service": "Kokoro TTS",
        "version": "1.1.1 (ä¿®å¤ç‰ˆ)",
        "status": "running" if tts_service else "degraded",
        "fixes": [
            "ä¿®å¤huggingface_hubå…¼å®¹é—®é¢˜",
            "æ”¹è¿›é”™è¯¯å¤„ç†",
            "ä¼˜åŒ–ç¯å¢ƒå˜é‡è®¾ç½®",
            "å¢å¼ºè°ƒè¯•ä¿¡æ¯"
        ],
        "endpoints": {
            "tts_stream": "/tts/stream",
            "tts_file": "/tts/file",
            "health": "/health",
            "voices": "/voices",
            "config": "/config",
            "debug": "/debug"
        }
    }

@app.get("/debug")
async def debug_info():
    """è°ƒè¯•ä¿¡æ¯æ¥å£"""
    import sys
    return {
        "python_version": sys.version,
        "working_directory": os.getcwd(),
        "environment_variables": {
            "HF_ENDPOINT": os.environ.get('HF_ENDPOINT'),
            "HUGGINGFACE_HUB_CACHE": os.environ.get('HUGGINGFACE_HUB_CACHE'),
            "HF_HOME": os.environ.get('HF_HOME'),
        },
        "cache_directories": {
            "huggingface_exists": os.path.exists('./cache/huggingface'),
            "torch_exists": os.path.exists('./cache/torch'),
            "logs_exists": os.path.exists('./logs'),
        },
        "service_status": {
            "pipeline_initialized": tts_service is not None and tts_service.pipeline is not None,
            "service_instance": tts_service is not None,
        }
    }

@app.get("/config")
async def get_config():
    """è·å–å½“å‰é…ç½®"""
    return {
        "sample_rate": tts_service.sample_rate if tts_service else "N/A",
        "max_chunk_length": tts_service.max_chunk_length if tts_service else "N/A",
        "chunk_delay": tts_service.chunk_delay if tts_service else "N/A",
        "mirror_sites": {
            "huggingface": os.getenv('HF_ENDPOINT'),
            "cache_dir": os.getenv('HUGGINGFACE_HUB_CACHE'),
        },
        "fixes_applied": [
            "huggingface_hub constants APIä¿®å¤",
            "ç¯å¢ƒå˜é‡ç›´æ¥è®¾ç½®",
            "å¯åŠ¨æ—¶å»¶è¿Ÿåˆå§‹åŒ–",
            "è¯¦ç»†é”™è¯¯ä¿¡æ¯"
        ]
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        service_working = tts_service is not None and tts_service.pipeline is not None
        
        health_status = {
            "status": "healthy" if service_working else "degraded",
            "tts_service": "available" if service_working else "unavailable",
            "initialization": "success" if service_working else "failed",
            "cache_dirs": {
                "huggingface": os.path.exists("./cache/huggingface"),
                "torch": os.path.exists("./cache/torch"),
                "logs": os.path.exists("./logs")
            },
            "environment": {
                "hf_endpoint": os.environ.get('HF_ENDPOINT'),
                "cache_configured": bool(os.environ.get('HUGGINGFACE_HUB_CACHE')),
            },
            "timestamp": time.time()
        }
        
        if service_working:
            health_status["performance"] = {
                "sample_rate": tts_service.sample_rate,
                "chunk_delay": tts_service.chunk_delay
            }
        
        return health_status
        
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": time.time()
        }

@app.get("/voices")
async def get_voices():
    """è·å–å¯ç”¨è¯­éŸ³åˆ—è¡¨"""
    return {
        "voices": [
            {
                "id": "zf_001",
                "name": "zf_001",
                "description": "ä¸­æ–‡å¥³å£° (ä¼˜åŒ–ç‰ˆ)",
                "language": "zh-CN",
                "optimized": True,
                "available": tts_service is not None
            }
        ],
        "default_voice": "zf_001",
        "supported_languages": ["zh-CN"],
        "service_status": "available" if tts_service else "unavailable"
    }

@app.post("/tts/stream")
async def tts_stream(request: TTSRequest):
    """æµå¼TTSæ¥å£"""
    if not tts_service:
        raise HTTPException(status_code=503, detail="TTSæœåŠ¡æœªå°±ç»ªï¼Œè¯·ç¨åé‡è¯•")
    
    logger.info(f"æ”¶åˆ°æµå¼TTSè¯·æ±‚: voice={request.voice}, speed={request.speed}")
    
    try:
        audio_stream = tts_service.generate_streaming_audio(
            text=request.text,
            voice=request.voice,
            speed=request.speed,
            chunk_size=request.chunk_size
        )
        
        return StreamingResponse(
            audio_stream,
            media_type="audio/wav",
            headers={
                "Content-Disposition": "inline; filename=speech.wav",
                "Cache-Control": "no-cache",
                "Access-Control-Allow-Origin": "*",
                "X-TTS-Mode": "stream",
                "X-TTS-Voice": request.voice,
                "X-TTS-Speed": str(request.speed)
            }
        )
        
    except Exception as e:
        logger.error(f"æµå¼TTSå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/tts/file")
async def tts_file(request: TTSRequest):
    """æ–‡ä»¶TTSæ¥å£"""
    if not tts_service:
        raise HTTPException(status_code=503, detail="TTSæœåŠ¡æœªå°±ç»ªï¼Œè¯·ç¨åé‡è¯•")
    
    logger.info(f"æ”¶åˆ°æ–‡ä»¶TTSè¯·æ±‚: voice={request.voice}, speed={request.speed}")
    
    try:
        # æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ•°æ®
        audio_chunks = []
        async for chunk in tts_service.generate_streaming_audio(
            text=request.text,
            voice=request.voice,
            speed=request.speed,
            chunk_size=request.chunk_size
        ):
            audio_chunks.append(chunk)
        
        if not audio_chunks:
            raise HTTPException(status_code=500, detail="æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘æ•°æ®")
        
        # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
        complete_audio = b''.join(audio_chunks)
        
        return Response(
            content=complete_audio,
            media_type="audio/wav",
            headers={
                "Content-Disposition": "inline; filename=speech.wav",
                "Content-Length": str(len(complete_audio)),
                "Cache-Control": "public, max-age=3600",
                "Access-Control-Allow-Origin": "*",
                "X-TTS-Mode": "file",
                "X-TTS-Voice": request.voice,
                "X-TTS-Speed": str(request.speed)
            }
        )
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶TTSå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# å¯åŠ¨å‚æ•°
if __name__ == "__main__":
    logger.info("ğŸš€ å¯åŠ¨ Kokoro TTS æœåŠ¡ (ä¿®å¤ç‰ˆ)")
    logger.info(f"ğŸ“ HuggingFaceç¼“å­˜: {os.getenv('HUGGINGFACE_HUB_CACHE')}")
    logger.info(f"ğŸŒ HuggingFaceé•œåƒ: {os.getenv('HF_ENDPOINT')}")
    
    uvicorn.run(
        "main:app",
        host="127.0.0.1",
        port=8001,
        reload=False,  # ä¿®å¤ç‰ˆæœ¬å»ºè®®ç¦ç”¨reload
        log_level="info"
    )